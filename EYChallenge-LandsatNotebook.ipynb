{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "id": "bdd2da0f-c53e-450a-ac0a-287cf5aea54f",
      "metadata": {
        "language": "python",
        "collapsed": true,
        "codeCollapsed": false
      },
      "source": "!pip install uv\n!uv pip install -r  requirements.txt\n!uv pip install streamlit\n!uv pip install -U ipywidgets\n!uv pip install shap snowflake-ml-python==1.19.0",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "8f7da842-99c9-4016-8613-df4672b40316",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "#Update this VERSION_NUM to version your features, models etc!\nVERSION_NUM = '0'\nDB = \"EY_DATA_CHALLENGE\" \nSCHEMA = \"DATA_SCHEMA\" \nROLE =\"ACCOUNTADMIN\"",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5a461d31-27aa-4236-bb27-b8734db82e11",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import pandas as pd\nimport numpy as np\nimport sklearn\nimport math\nimport pickle\nimport shap\nfrom datetime import datetime\nimport streamlit as st\nfrom xgboost import XGBClassifier\n\n# Snowpark ML\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.modeling.tune import get_tuner_context\nfrom snowflake.ml.modeling import tune\nfrom entities import search_algorithm\n\n#Snowflake feature store\nfrom snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n\n# Snowpark session\nfrom snowflake.snowpark import DataFrame\nfrom snowflake.snowpark.functions import col, to_timestamp, min, max, month, dayofweek, dayofyear, avg, date_add, sql_expr,year,quarter,date_trunc\nfrom snowflake.snowpark.types import IntegerType\nfrom snowflake.snowpark import Window\n\n#setup snowpark session\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nsession.use_database(DB)\nsession.use_schema(SCHEMA)\nsession",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6fed8ce5-a4ae-4bc6-b658-c246a36e0c4f",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Supress Warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import common GIS tools\nimport numpy as np\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\n# Import Planetary Computer tools\nimport pystac_client\nimport planetary_computer as pc\nfrom odc.stac import stac_load",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bee563be-2f64-4109-8076-bef24919b935",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Sample region in South Africa\n# Contains Water Quality Sample Site #184 and #186 on Wilge River\n\n#lat_long = (-26.510278, 28.351389) # Lat-Lon centroid location\n#lat_long = (-28.760833,17.730278) # Sample data set validation \nlat_long = (-26.9847222,26.63227778)\nbox_size_deg = 0.15 # Surrounding box in degrees",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d5ec2880-f150-4b61-8817-487c223effdf",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Calculate the Lat-Lon bounding box region\nmin_lon = lat_long[1]-box_size_deg/2\nmin_lat = lat_long[0]-box_size_deg/2\nmax_lon = lat_long[1]+box_size_deg/2\nmax_lat = lat_long[0]+box_size_deg/2\nprint (f\"min_lon:{min_lon}\")\nprint (f\"min_lat:{min_lat}\")\nprint (f\"max_lon:{max_lon}\")\nprint (f\"max_lat:{max_lat}\")\nbounds = (min_lon, min_lat, max_lon, max_lat)\nprint(f\"bounds:{bounds}\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a54ffe71-8d22-4ce8-adfe-15606f265839",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Define the time window\ntime_window=\"2011-01-01/2015-12-31\"\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0fa84939-ac17-48eb-8d12-b0d3e7103d3e",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "stac = pystac_client.Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\nsearch = stac.search(\n    collections=[\"landsat-c2-l2\"], \n    bbox=bounds, \n    datetime=time_window,\n    query={\"platform\": {\"in\": [\"landsat-7\", \"landsat-8\"]}, \"eo:cloud_cover\": {\"lt\": 10}},\n)\nitems = list(search.get_all_items())\nprint('This is the number of scenes that touch our region:',len(items))",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9c94e1f3-f36e-43ed-a142-915560a51f3f",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "\nNext, we'll load the data into an xarray DataArray using the Open Data Cube (ODC) STAC odc-stac library that is included with the Planetary Computer. The ODC odc is an open source geospatial data management and analysis software project that is used globally for many projects (e.g., Digital Earth Africa). The ODC-STAC code will load the selected items from the catalog search, select the desired spectral bands, including the \"qa_pixel\" cloud filtering band, reproject into Lat-Lon coordinates (EPSG:4326) at 30-meters resolution (typical of Landsat pixel resolution), and clip the region to the spatial bounding box."
    },
    {
      "id": "d251a150-6e7c-4e11-9601-d710fc9937fa",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Define the pixel resolution for the final product\n# Define the scale according to our selected crs, so we will use degrees\nresolution = 30  # meters per pixel \nscale = resolution / 111320.0 # degrees per pixel for CRS:4326 ",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f1ffc38a-51dc-4713-82ec-6f51b43f491e",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "xx = stac_load(\n    items,\n    bands=[\"red\", \"green\", \"blue\", \"nir08\", \"swir16\", \"swir22\", \"qa_pixel\"],\n    crs=\"EPSG:4326\", # Latitude-Longitude\n    resolution=scale, # Degrees\n    chunks={\"x\": 2048, \"y\": 2048},\n    patch_url=pc.sign,\n    bbox=bounds\n)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8d1e5d0f-530c-4716-819e-3d7d22d753bd",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Apply scaling and offsets for Landsat Collection-2 (reference below) to the spectral bands ONLY\n# https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2\nxx['red'] = (xx['red']*0.0000275)-0.2\nxx['green'] = (xx['green']*0.0000275)-0.2\nxx['blue'] = (xx['blue']*0.0000275)-0.2\nxx['nir08'] = (xx['nir08']*0.0000275)-0.2\nxx['swir16'] = (xx['swir16']*0.0000275)-0.2\nxx['swir22'] = (xx['swir22']*0.0000275)-0.2",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bf3a2b75-7d79-4a1c-8b10-c61c2e6867c5",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# View the dimensions of our XARRAY and the variables\ndisplay(xx)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "583aa742-e846-46e9-a15e-b08f3f3b3c06",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Test that packages work together\nimport xarray as xr\nimport dask\nimport dask.array as da\nimport zarr\nimport numpy as np\n\nprint(\"Package Versions:\")\nprint(f\"  xarray: {xr.__version__}\")\nprint(f\"  dask: {dask.__version__}\")\nprint(f\"  zarr: {zarr.__version__}\")\n\n# Test dask chunk manager\nprint(\"\\nTesting dask chunk manager...\")\ntry:\n    test_array = da.ones((10, 10), chunks=(5, 5))\n    test_xr = xr.DataArray(test_array)\n    print(f\"✓ Dask chunks working: {test_xr.chunks}\")\nexcept Exception as e:\n    print(f\"✗ Error: {e}\")\n\nprint(\"\\n✓ Ready to use!\")\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4fe67315-02c4-4225-8288-d5b750e81a07",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "plot_xx = xx[[\"red\",\"green\",\"blue\"]].to_array()\nplot_xx.plot.imshow(col='time', col_wrap=4, robust=True, vmin=0, vmax=0.3)\nplt.show()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9d59011e-b355-4a83-86ae-9ca004019b71",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "data = xx[[\"red\",\"green\",\"blue\"]].to_array(name='value')\ndata = data.compute()  # Force computation if using dask\ndisplay(data)\ndf = data.to_dataframe().unstack()\nprint(df)\n#df.to_csv('output.csv')\n\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2b1900cb-299c-4737-b30a-869c15a7fe31",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "Show the xarray definition",
        "title": "Show the xarray definition"
      },
      "source": "import pandas as pd\n\n# Get the array and reshape as needed\n#data = xx[[\"red\",\"green\",\"blue\"]].to_array()\ntime_slice = 1\nprint(xx[[\"red\",\"green\",\"blue\"]])\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d0e7eb69-e0cb-41f4-b3f1-caf601fc789f",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "Print a specific value from the xarray",
        "title": "Print a specific value from the xarray"
      },
      "source": " \nresult = xx.sel(\n    time=xx.time[0],           # First time step\n    latitude=-26.5,             # Your desired latitude\n    longitude=28.3,             # Your desired longitude\n    method=\"nearest\"            # Find closest coordinate\n)\n\nprint(\"Red:\", result[\"red\"].values)\nprint(\"Green:\", result[\"green\"].values)\nprint(\"Blue:\", result[\"blue\"].values)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8efdd4cf-1a58-4333-88b7-88c1fe1bb0ec",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "See the xarray dimension",
        "title": "See the xarray dimension"
      },
      "source": "print(f\"Total time dimensions: {len(xx.time)}\")\nprint(f\"Total latitude values: {len(xx.latitude)}\")\nprint(f\"Total longitude values: {len(xx.longitude)}\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dabe8dd1-5112-40d9-87ff-9292303ee15f",
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "Loading the data to Snowflake table - refined.",
        "title": "Loading the data to Snowflake table - refined."
      },
      "source": "# Drop the table first\nsession.sql(\"DROP TABLE IF EXISTS LANDSAT_FETCH\").collect()\nsession.sql(\"DROP TABLE IF EXISTS LANDSAT_FETCH_TEMP\").collect()\n\n# Convert to dataframe\ndf = xx[[\"red\",\"green\",\"blue\"]].to_dataframe()\ndf_reset = df.reset_index()\n\n# Convert time to STRING format that Snowflake can parse\ndf_reset['time'] = pd.to_datetime(df_reset['time']).dt.strftime('%Y-%m-%d %H:%M:%S.%f')\n\n# Rename and clean up\ndf_reset = df_reset.rename(columns={'time': 'OBS_TIME'})\ndf_reset = df_reset.drop(columns=['spatial_ref'], errors='ignore')\ndf_reset.columns = df_reset.columns.str.upper()\n\nprint(\"Dtypes after string conversion:\")\nprint(df_reset.dtypes)\nprint(\"\\nSample:\")\nprint(df_reset.head())\n\n# Write to temporary table as strings\nsession.write_pandas(\n    df_reset, \n    table_name=\"LANDSAT_FETCH_TEMP\",\n    auto_create_table=True,\n    overwrite=True\n)\n\n# Create final table with proper TIMESTAMP and cast\nsession.sql(\"\"\"\n    CREATE OR REPLACE TABLE LANDSAT_FETCH AS\n    SELECT \n        TO_TIMESTAMP(OBS_TIME, 'YYYY-MM-DD HH24:MI:SS.FF') AS OBS_TIME,\n        LATITUDE,\n        LONGITUDE,\n        RED,\n        GREEN,\n        BLUE\n    FROM LANDSAT_FETCH_TEMP\n\"\"\").collect()\n\n# Drop temp table\nsession.sql(\"DROP TABLE LANDSAT_FETCH_TEMP\").collect()\n\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "919e0ca1-982f-4ff8-ad60-0199996eaebb",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Verify\nsession.sql(\"DESCRIBE TABLE LANDSAT_FETCH\").show()\nsession.sql(\"SELECT OBS_TIME, LATITUDE, LONGITUDE,RED,GREEN,BLUE FROM LANDSAT_FETCH LIMIT 5\").show()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bd5cda10-904a-42a7-8449-a23994037f97",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Loop through first 10 pixels only\nfor t in range(2):  # First 2 time steps\n    for lat in range(5):  # First 5 latitudes\n        for lon in range(5):  # First 5 longitudes\n            time_val = xx.time[t].values\n            lat_val = xx.latitude[lat].values\n            lon_val = xx.longitude[lon].values\n            red_val = xx['red'].isel(time=t, latitude=lat, longitude=lon).values\n            green_val = xx['green'].isel(time=t, latitude=lat, longitude=lon).values\n            blue_val = xx['blue'].isel(time=t, latitude=lat, longitude=lon).values\n            \n            print(f\"T: {time_val}, Lat: {lat_val:.4f}, Lon: {lon_val:.4f}, \"\n                  f\"R: {red_val:.2f}, G: {green_val:.2f}, B: {blue_val:.2f}\")\n    \n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "02be380b-ae79-4327-8d26-c46b4cf816af",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "#Create a dict with keys for feature names and values containing transform code\n\nfeature_eng_dict = dict()\n\n#Timstamp features\nfeature_eng_dict[\"MONTH\"] = month(\"SAMPLE_DATE\")\nfeature_eng_dict[\"QUARTER\"] = quarter(\"SAMPLE_DATE\") \nfeature_eng_dict[\"YEAR\"] = year(\"SAMPLE_DATE\") \nfeature_eng_dict[\"QUARTER_DATE\"] = date_trunc(\"quarter\", col(\"SAMPLE_DATE\"))\n\n##Spectral Indexes\n\n#NDMI (Normalized Difference Moisture Index) - Useful for detecting wetland conditions affecting water quality\n#\tFormula: (NIR - SWIR) / (NIR + SWIR)\n#\tMeasures water content in vegetation and soil moisture\n\n#MNDWI (Modified Normalized Difference Water Index) -Better for turbid water identification\n#\tFormula: (Green - SWIR) / (Green + SWIR)\n#\tEnhances water body detection, suppresses soil/vegetation noise\n\n#1. NDWI: (Green - NIR) / (Green + NIR) - Water body delineation\n#2. NDTI: (Red - Green) / (Red + Green) - Turbidity measurement\n\n## EC Indexes \n#3. Salinity Index: (Red - NIR) / (Red + NIR)\n#4. Band ratios: Blue/Red, SWIR/NIR combinations\n\n## Useful Indices for DRP Prediction:\n\n#5.Chlorophyll Index (CI): (NIR/Red) - 1, indicates algae from phosphorus\nfeature_eng_dict[\"CI\"] = col(\"NIR\") / col()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "06db520f-2a6e-4aef-9d1f-4a3219d623ab",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "",
      "outputs": [],
      "execution_count": null
    }
  ]
}